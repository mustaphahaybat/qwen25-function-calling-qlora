# ğŸ¤– Fine-Tuning Qwen2.5-3B for Function Calling with QLoRA

Fine-tuning a small LLM to improve tool/function calling accuracy
using QLoRA on Google Colab Free Tier (T4 GPU).

## ğŸ“Š Results

| Config | Overall | Tool-call | Loss |
|--------|---------|-----------|------|
| Base model | 80.0% | 29.6% | - |
| steps=120, lr=2e-4 | 93.0% | 85.2% | 0.521 |
| steps=60, lr=2e-4 | 90.0% | 70.4% | 0.396 |

**Key improvement: Tool-call accuracy 29.6% â†’ 85.2% (+55.6%) ğŸš€**

## ğŸ› ï¸ Setup

- **Model:** Qwen2.5-3B-Instruct (4-bit quantized)
- **Technique:** QLoRA (LoRA r=16) â€” only 0.96% of parameters trained
- **Dataset:** glaiveai/glaive-function-calling-v2 (2,500 train / 200 eval)
- **Hardware:** Google Colab Free Tier (T4 GPU, 15.6GB VRAM)
- **Framework:** Unsloth + TRL SFTTrainer

## ğŸš€ Quick Start

Open directly in Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](
https://colab.research.google.com/github/YOUR_USERNAME/qwen25-function-calling-qlora/blob/main/qwen25_function_calling_qlora.ipynb)

## ğŸ“ Structure
```
â”œâ”€â”€ qwen25_function_calling_qlora.ipynb  # Main notebook
â””â”€â”€ README.md
```

## ğŸ”‘ Key Findings

1. QLoRA trains only 0.96% of parameters but achieves +55.6% improvement
2. Balanced evaluation set is critical for meaningful metrics
3. steps=120 optimal â€” more steps showed diminishing returns
4. Full training completed in 13 minutes on free T4 GPU

## ğŸ‘¤ Author

**Mustafa Haybat GÃ¶zgÃ¶z**  
[LinkedIn](https://www.linkedin.com/in/mustafa-haybat-gozgoz35)
